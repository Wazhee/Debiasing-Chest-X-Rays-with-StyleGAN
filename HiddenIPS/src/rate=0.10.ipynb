{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05cdc8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-io==0.35.0\n",
      "  Downloading tensorflow_io-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.35.0 (from tensorflow-io==0.35.0)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Downloading tensorflow_io-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
      "Successfully installed tensorflow-io-0.35.0 tensorflow-io-gcs-filesystem-0.35.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nibabel\n",
      "  Downloading nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting importlib-resources>=5.12 (from nibabel)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.8.0)\n",
      "Downloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: importlib-resources, nibabel\n",
      "\u001b[33m  WARNING: The scripts nib-conform, nib-convert, nib-dicomfs, nib-diff, nib-ls, nib-nifti-dx, nib-roi, nib-stats, nib-tck2trk, nib-trk2tck and parrec2nii are installed in '/home/runai-home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed importlib-resources-6.5.2 nibabel-5.3.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pydicom\n",
      "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "\u001b[33m  WARNING: The script pydicom is installed in '/home/runai-home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pydicom-3.0.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/runai-home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-io==0.35.0\n",
    "!pip install nibabel\n",
    "!pip install pydicom\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9e5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:00:45.082663: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-16 17:00:45.082717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-16 17:00:45.082749: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-16 17:00:45.091384: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU list:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPU list: \", gpus)\n",
    "# for i in range(len(gpus)):\n",
    "#     tf.config.experimental.set_memory_growth(gpus[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc4cde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runai-home/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "from test import *\n",
    "from analysis import *\n",
    "\n",
    "model = \"densenet\"\n",
    "def train_test_aim_2(sex=None, age=None, augmentation=False, rate=[0], demo=\"age\"):\n",
    "  train_aim_2(model, sex, age, augmentation, rate, demo)\n",
    "  test_aim_2(model, test_ds, sex, age, augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f277c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:00:49.126170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38293 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:43:00.0, compute capability: 8.0\n",
      "2025-02-16 17:00:49.753641: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2025-02-16 17:00:49.758480: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:01:18.797900: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8906\n",
      "2025-02-16 17:01:21.587597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3a85c793c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-16 17:01:21.587690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-02-16 17:01:21.596769: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-16 17:01:21.695667: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - ETA: 0s - loss: 0.4294 - auc: 0.8011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 233s 615ms/step - loss: 0.4294 - auc: 0.8011 - val_loss: 0.3918 - val_auc: 0.8551 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 202s 681ms/step - loss: 0.3897 - auc: 0.8397 - val_loss: 0.3884 - val_auc: 0.8671 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 204s 687ms/step - loss: 0.3741 - auc: 0.8541 - val_loss: 0.3511 - val_auc: 0.8747 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 197s 662ms/step - loss: 0.3666 - auc: 0.8614 - val_loss: 0.3457 - val_auc: 0.8795 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 151s 506ms/step - loss: 0.3629 - auc: 0.8639 - val_loss: 0.3492 - val_auc: 0.8803 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 142s 478ms/step - loss: 0.3567 - auc: 0.8698 - val_loss: 0.3480 - val_auc: 0.8819 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 144s 486ms/step - loss: 0.3544 - auc: 0.8717 - val_loss: 0.3452 - val_auc: 0.8832 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 150s 504ms/step - loss: 0.3531 - auc: 0.8727 - val_loss: 0.3408 - val_auc: 0.8893 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 155s 521ms/step - loss: 0.3497 - auc: 0.8752 - val_loss: 0.3308 - val_auc: 0.8913 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 159s 535ms/step - loss: 0.3472 - auc: 0.8777 - val_loss: 0.3259 - val_auc: 0.8949 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 156s 526ms/step - loss: 0.3485 - auc: 0.8767 - val_loss: 0.3270 - val_auc: 0.8954 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "292/292 [==============================] - 149s 499ms/step - loss: 0.3428 - auc: 0.8809 - val_loss: 0.3274 - val_auc: 0.8972 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "292/292 [==============================] - 148s 499ms/step - loss: 0.3435 - auc: 0.8809 - val_loss: 0.3264 - val_auc: 0.8985 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "292/292 [==============================] - 145s 487ms/step - loss: 0.3411 - auc: 0.8829 - val_loss: 0.3286 - val_auc: 0.9000 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "292/292 [==============================] - 135s 453ms/step - loss: 0.3396 - auc: 0.8840 - val_loss: 0.3154 - val_auc: 0.9027 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "292/292 [==============================] - 133s 446ms/step - loss: 0.3386 - auc: 0.8843 - val_loss: 0.3171 - val_auc: 0.9026 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "292/292 [==============================] - 134s 452ms/step - loss: 0.3347 - auc: 0.8873 - val_loss: 0.3146 - val_auc: 0.9043 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "292/292 [==============================] - 132s 446ms/step - loss: 0.3332 - auc: 0.8891 - val_loss: 0.3159 - val_auc: 0.9049 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "292/292 [==============================] - 153s 517ms/step - loss: 0.3307 - auc: 0.8899 - val_loss: 0.3095 - val_auc: 0.9091 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3280 - auc: 0.8928"
     ]
    }
   ],
   "source": [
    "train_test_aim_2(sex='M', augmentation=False, rate=[0.05], demo=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11262cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
